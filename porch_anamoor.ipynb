{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nnl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM02yfVNWVvl9EmLmhm0r+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/themanoftalent/NLP/blob/main/porch_anamoor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmHDVMa3vH0f"
      },
      "source": [
        "import re\n",
        "from typing import List "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A9N_lzoXBIH"
      },
      "source": [
        "def username(text:str) -> List[str]:\n",
        "  print(re.findall(r\"([^\\s@]+)@\\S+\", text))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kWWUeksXLdr",
        "outputId": "9f6521ec-32e2-4cce-b35b-fdcf1323170f"
      },
      "source": [
        "a= \"New regsitered users are : john.doe@gmail.com, john@gmail.com\"\n",
        "username(a)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['john.doe', 'john']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kedIrpZuXbMu"
      },
      "source": [
        "###########3"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmtzLVYkX0iZ"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from collections import Counter"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XHSJIKKbIy5",
        "outputId": "45056727-5345-420c-8d1e-acfff827a566"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPJx-oUGX4MV"
      },
      "source": [
        "def cleaning(data):\n",
        "    stop_words = stopwords.words('english')\n",
        "    #lem = WordNetLemmatizer()\n",
        "    #1 . Tokenize\n",
        "    text_tokens = word_tokenize(data)\n",
        "    #2. Remove Puncs\n",
        "    #tokens_without_punc = [w for w in text_tokens if w.isalpha() or w.isdigit()]\n",
        "    #3. Removing Stopwords\n",
        "    tokens_without_sw = [t for t in text_tokens if t not in stop_words]\n",
        "    #4. lemma\n",
        "   #text_cleaned = [lem.lemmatize(t) for t in tokens_without_sw]\n",
        "    #join\n",
        "    return ' '.join(tokens_without_sw)\n",
        "  \n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "x-4r1NjNaoBL",
        "outputId": "9e0c4790-1d9d-4ede-c0ca-ae77e94479ac"
      },
      "source": [
        "text = \"\"\" It says the world's wealthiest 1% produce double the combined carbon emission of the poor est 50%, according to the UN.  The wealthiest 5% alone - the so-called \"poll uter elite\" - contributed 37% of emission growth between 1990 and 2015.\n",
        "\"\"\"\n",
        "cleaning(text)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"It says world 's wealthiest 1 % produce double combined carbon emission poor est 50 % , according UN . The wealthiest 5 % alone - so-called `` poll uter elite '' - contributed 37 % emission growth 1990 2015 .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ad3J6NZbF6a"
      },
      "source": [
        "############# "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucCWS4qkfVkm"
      },
      "source": [
        "def compose(x):\n",
        "  return x+1\n",
        "    if len(list) == 1:\n",
        "        return lambda x:list[0](x)\n",
        "    list.reverse()\n",
        "    final=lambda x:x\n",
        "    for f in list:\n",
        "        final=lambda x:f(final(x))\n",
        "    return final"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm5ccH8Hh5np"
      },
      "source": [
        ""
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKHGftLHh6_3"
      },
      "source": [
        "f1 = f1_score(testy, yhat_classes)\n",
        "print('F1 score: %f' % f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-drqzDeumIC_"
      },
      "source": [
        "# Python3 code to Check for\n",
        "# balanced parentheses in an expression\n",
        "def check(expression):\n",
        "\t\n",
        "\topen_tup = tuple('({[')\n",
        "\tclose_tup = tuple(')}]')\n",
        "\tmap = dict(zip(open_tup, close_tup))\n",
        "\tqueue = []\n",
        "\n",
        "\tfor i in expression:\n",
        "\t\tif i in open_tup:\n",
        "\t\t\tqueue.append(map[i])\n",
        "\t\telif i in close_tup:\n",
        "\t\t\tif not queue or i != queue.pop():\n",
        "\t\t\t\treturn \"False\"\n",
        "\tif not queue:\n",
        "\t\treturn \"True\"\n",
        "\telse:\n",
        "\t\treturn \"False\"\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aDMrS8MJmIz6",
        "outputId": "67127ec4-51d7-46a3-a632-280b2c123ab3"
      },
      "source": [
        "check(\"{[(])}\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'False'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1ZDTDXX0mSNL",
        "outputId": "edc324e2-c2f0-43b0-f4f0-c65b8b378135"
      },
      "source": [
        "check(\"[()}\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'False'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD76-iH0niTu"
      },
      "source": [
        "#newton method"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xf1NMFDpcxH"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEij-vtTpZBT"
      },
      "source": [
        "# initial guess\n",
        "guess = torch.tensor([1], dtype=torch.float64, requires_grad = True) \n",
        "\n",
        "# function to optimize\n",
        "def my_func(x): \n",
        "    return x - torch.cos(x)\n",
        "\n",
        "def newton(func, runs=5): \n",
        "    for _ in range(runs): \n",
        "        # evaluate our function with current value of `guess`\n",
        "        value = my_func(guess)\n",
        "        value.backward()\n",
        "        # update our `guess` based on the gradient\n",
        "        guess.data -= (value / guess.grad).data\n",
        "        # zero out current gradient to hold new gradients in next iteration \n",
        "        guess.grad.data.zero_() \n",
        "    return guess.data # return our final `guess` after 5 updates\n",
        "\n",
        "# # call starts\n",
        "# result = newton(my_func, guess)\n",
        "\n",
        "# # output of `result`\n",
        "# tensor([0.7391], dtype=torch.float64)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bPLfuaUpbQ0",
        "outputId": "0e78b7f8-88ee-42e7-b656-f1e38d2b97da"
      },
      "source": [
        "my_func(torch.tensor(1.))==torch.tensor(2.2)\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si1oXW2NqIWi",
        "outputId": "8c8b82cf-949e-4fb8-d42b-df2778aaeb2e"
      },
      "source": [
        "newton(torch.tensor(2.25))==torch.tensor(6.25)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOa8RNQHqhyW",
        "outputId": "e1b3c2be-bd5c-4ceb-bf49-2bbb31219bc2"
      },
      "source": [
        "my_func(torch.tensor(-1.2))==torch.tensor(0)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpN78srqquw0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}