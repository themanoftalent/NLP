{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "2- stop words.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/themanoftalent/NLP/blob/main/2_stop_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwhaCmOHe0G5",
        "outputId": "92385a35-6abc-4f8f-da8d-b2a04c246f92"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYE7XIz_e9sO"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RtRp5j7ey9-"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTDiq0igey-A"
      },
      "source": [
        "text = \"Alan Turing, British mathematician, computer scientist and cryptologist. He is considered the founder of computer science. He put forward a criterion for whether machines and computers can think or not with the Turing test he developed.\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGft79vyey-B"
      },
      "source": [
        "stopwordz = stopwords.words(\"english\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2El5OGbfS6x"
      },
      "source": [
        "lets_token_word = word_tokenize(text)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGFxBGyEfS3y",
        "outputId": "1bf88014-61d7-4781-9967-72d9b86f4095"
      },
      "source": [
        "output = []\n",
        "for cumle in lets_token_word:\n",
        "  if cumle not in stopwordz:\n",
        "    output.append(cumle)\n",
        "output"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Alan',\n",
              " 'Turing',\n",
              " ',',\n",
              " 'British',\n",
              " 'mathematician',\n",
              " ',',\n",
              " 'computer',\n",
              " 'scientist',\n",
              " 'cryptologist',\n",
              " '.',\n",
              " 'He',\n",
              " 'considered',\n",
              " 'founder',\n",
              " 'computer',\n",
              " 'science',\n",
              " '.',\n",
              " 'He',\n",
              " 'put',\n",
              " 'forward',\n",
              " 'criterion',\n",
              " 'whether',\n",
              " 'machines',\n",
              " 'computers',\n",
              " 'think',\n",
              " 'Turing',\n",
              " 'test',\n",
              " 'developed',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_v6WMHJfS1K"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LMrF7XifSqV",
        "outputId": "3ad94cd1-855b-4e84-c9b4-9fbcf185fcee"
      },
      "source": [
        "sent = \"I will walk 500 miles and I would walk 500 more, just to be the man who walks a thousand miles to fall down at your door!\"\n",
        "\n",
        "print(word_tokenize(sent))\n",
        "print(\"\")\n",
        "print(sent_tokenize(sent))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'will', 'walk', '500', 'miles', 'and', 'I', 'would', 'walk', '500', 'more', ',', 'just', 'to', 'be', 'the', 'man', 'who', 'walks', 'a', 'thousand', 'miles', 'to', 'fall', 'down', 'at', 'your', 'door', '!']\n",
            "\n",
            "['I will walk 500 miles and I would walk 500 more, just to be the man who walks a thousand miles to fall down at your door!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2wutnOwga94",
        "outputId": "96507841-dbcc-43e3-b734-cc685b9a4451"
      },
      "source": [
        "filtered= []\n",
        "for cumles in word_tokenize(sent):\n",
        "  if cumles not in stopwordz:\n",
        "    filtered.append(cumles)\n",
        "\n",
        "filtered"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'walk',\n",
              " '500',\n",
              " 'miles',\n",
              " 'I',\n",
              " 'would',\n",
              " 'walk',\n",
              " '500',\n",
              " ',',\n",
              " 'man',\n",
              " 'walks',\n",
              " 'thousand',\n",
              " 'miles',\n",
              " 'fall',\n",
              " 'door',\n",
              " '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3ZNKB2jgsHC"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZYLNrdxg2VO",
        "outputId": "e75fe600-8c05-47a6-f0b6-08e21f3d2a3b"
      },
      "source": [
        "from spacy.lang.en import English\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "nlp = English()\n",
        "\n",
        "text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
        "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
        "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
        "\n",
        "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
        "my_doc = nlp(text)\n",
        "\n",
        "# Create list of word tokens\n",
        "token_listesi = []\n",
        "for token in my_doc:\n",
        "    token_listesi.append(token.text)  \n",
        "\n",
        "\n",
        "\n",
        "# Create list of word tokens after removing stopwords\n",
        "filtrelenmis =[] \n",
        "\n",
        "for word in token_listesi:\n",
        "    lexeme = nlp.vocab[word]\n",
        "    if lexeme.is_stop == False:\n",
        "        filtrelenmis.append(word) \n",
        "\n",
        "print(token_listesi)\n",
        "print(\"\")\n",
        "print(filtrelenmis) "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['He', 'determined', 'to', 'drop', 'his', 'litigation', 'with', 'the', 'monastry', ',', 'and', 'relinguish', 'his', 'claims', 'to', 'the', 'wood', '-', 'cuting', 'and', '\\n', 'fishery', 'rihgts', 'at', 'once', '.', 'He', 'was', 'the', 'more', 'ready', 'to', 'do', 'this', 'becuase', 'the', 'rights', 'had', 'become', 'much', 'less', 'valuable', ',', 'and', 'he', 'had', '\\n', 'indeed', 'the', 'vaguest', 'idea', 'where', 'the', 'wood', 'and', 'river', 'in', 'question', 'were', '.']\n",
            "\n",
            "['determined', 'drop', 'litigation', 'monastry', ',', 'relinguish', 'claims', 'wood', '-', 'cuting', '\\n', 'fishery', 'rihgts', '.', 'ready', 'becuase', 'rights', 'valuable', ',', '\\n', 'vaguest', 'idea', 'wood', 'river', 'question', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhFxxUV2hLQp"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxQV0jQkhMmz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}