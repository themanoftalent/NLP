{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Porter Stemmer and stop .ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/themanoftalent/NLP/blob/main/Post_tag_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-BBlXKYHTMj"
      },
      "source": [
        "text= \"\"\"We get the body of text elegantly converted into a list. The above tokenization without NLTK would take hours and hours of coding with regular expressions! \n",
        "You may wonder about the punctuation marks though. This is something we will have to care of separately. We could also use other tokenizers like the PunktSentenceTokenizer, \n",
        "which is a pre-trained unsupervised ML model. We can even train it the ourselves if we want using our own dataset. Keep an eye out for my future articles. insert shameless self-promoting call\n",
        " to follow I played the play playfully as the players were playing in the play with playfullness\"\"\""
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKmh4hDiHWW0",
        "outputId": "be3c0e98-b8ab-4641-9437-1c968d6c3b55"
      },
      "source": [
        "import nltk \n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import re"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeD8yaoAmoG6"
      },
      "source": [
        "clean_text = re.sub(\"\\.,!\",\"\",text)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKrD7VVEmuPp"
      },
      "source": [
        ""
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqy-y811lpur"
      },
      "source": [
        "word_token=word_tokenize(clean_text)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ceyTjDIlon1",
        "outputId": "26f4a223-95a1-46e2-e588-83f49516434c"
      },
      "source": [
        "clean_token= []\n",
        "for wordi in word_token:\n",
        "  if wordi not in stopwords.words(\"english\"):\n",
        "    clean_token.append(wordi)\n",
        "\n",
        "print(clean_token)\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['We', 'get', 'body', 'text', 'elegantly', 'converted', 'list', '.', 'The', 'tokenization', 'without', 'NLTK', 'would', 'take', 'hours', 'hours', 'coding', 'regular', 'expressions', '!', 'You', 'may', 'wonder', 'punctuation', 'marks', 'though', '.', 'This', 'something', 'care', 'separately', '.', 'We', 'could', 'also', 'use', 'tokenizers', 'like', 'PunktSentenceTokenizer', ',', 'pre-trained', 'unsupervised', 'ML', 'model', '.', 'We', 'even', 'train', 'want', 'using', 'dataset', '.', 'Keep', 'eye', 'future', 'articles', '.', 'insert', 'shameless', 'self-promoting', 'call', 'follow', 'I', 'played', 'play', 'playfully', 'players', 'playing', 'play', 'playfullness']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SihqL9M-HYkQ"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFLEhXG5lKYa"
      },
      "source": [
        "tag_token=pos_tag(clean_token)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbzCBmz7lN2s",
        "outputId": "92aafff8-5b62-44c8-c797-1a3321e7e499"
      },
      "source": [
        "tag_token"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('We', 'PRP'),\n",
              " ('get', 'VBP'),\n",
              " ('body', 'JJ'),\n",
              " ('text', 'NN'),\n",
              " ('elegantly', 'RB'),\n",
              " ('converted', 'VBN'),\n",
              " ('list', 'NN'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('tokenization', 'NN'),\n",
              " ('without', 'IN'),\n",
              " ('NLTK', 'NNP'),\n",
              " ('would', 'MD'),\n",
              " ('take', 'VB'),\n",
              " ('hours', 'NNS'),\n",
              " ('hours', 'NNS'),\n",
              " ('coding', 'VBG'),\n",
              " ('regular', 'JJ'),\n",
              " ('expressions', 'NNS'),\n",
              " ('!', '.'),\n",
              " ('You', 'PRP'),\n",
              " ('may', 'MD'),\n",
              " ('wonder', 'VB'),\n",
              " ('punctuation', 'NN'),\n",
              " ('marks', 'NNS'),\n",
              " ('though', 'IN'),\n",
              " ('.', '.'),\n",
              " ('This', 'DT'),\n",
              " ('something', 'NN'),\n",
              " ('care', 'NN'),\n",
              " ('separately', 'RB'),\n",
              " ('.', '.'),\n",
              " ('We', 'PRP'),\n",
              " ('could', 'MD'),\n",
              " ('also', 'RB'),\n",
              " ('use', 'VB'),\n",
              " ('tokenizers', 'NNS'),\n",
              " ('like', 'IN'),\n",
              " ('PunktSentenceTokenizer', 'NNP'),\n",
              " (',', ','),\n",
              " ('pre-trained', 'JJ'),\n",
              " ('unsupervised', 'JJ'),\n",
              " ('ML', 'NNP'),\n",
              " ('model', 'NN'),\n",
              " ('.', '.'),\n",
              " ('We', 'PRP'),\n",
              " ('even', 'RB'),\n",
              " ('train', 'VBP'),\n",
              " ('want', 'VBP'),\n",
              " ('using', 'VBG'),\n",
              " ('dataset', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Keep', 'VB'),\n",
              " ('eye', 'NN'),\n",
              " ('future', 'JJ'),\n",
              " ('articles', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('insert', 'JJ'),\n",
              " ('shameless', 'JJ'),\n",
              " ('self-promoting', 'NN'),\n",
              " ('call', 'NN'),\n",
              " ('follow', 'VBP'),\n",
              " ('I', 'PRP'),\n",
              " ('played', 'VBD'),\n",
              " ('play', 'NN'),\n",
              " ('playfully', 'RB'),\n",
              " ('players', 'NNS'),\n",
              " ('playing', 'VBG'),\n",
              " ('play', 'NN'),\n",
              " ('playfullness', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aztC_5iQlVi3"
      },
      "source": [
        ""
      ],
      "execution_count": 93,
      "outputs": []
    }
  ]
}